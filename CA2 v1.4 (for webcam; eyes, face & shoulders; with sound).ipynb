{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Seems this is needed for jupyter notebook to find the correct site packages\n",
    "# Change this to where ever the yzsus environment is installed\n",
    "sys.path.append(\"D:\\DocumentsDDrive\\Installed_Files\\Anaconda3\\envs\\yzsus\\Lib\\site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import playsound\n",
    "from scipy import ndimage\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "\n",
    "# # OPTION1: Set it here\n",
    "# # Due to compute we don't process every frame but every Xth frame\n",
    "# processed_Xth_frame = 3\n",
    " \n",
    "# # Specify the input image dimensions\n",
    "# frameWidth = 960 \n",
    "# frameHeight = 720\n",
    "\n",
    "# # Thresholds for the rule-based model\n",
    "# eye_threshold_in_pixels = 5\n",
    "# tilt_frontback_threshold_in_pixels = 20\n",
    "# tilt_leftright_threshold_in_degrees = 15\n",
    "# tilt_shoulder_threshold_in_pixels = 20\n",
    "# overall_okay_threshold = 0.5\n",
    "\n",
    "# # The duration in seconds before...\n",
    "# # The alarm is sounded for wrong posture.\n",
    "# wrong_posture_duration_in_seconds = 3\n",
    "# # The text asks you to get up and move.\n",
    "# seated_duration_in_seconds = 10\n",
    "\n",
    "# soundclip_filepath = \"./bleepsound_cut.mp3\"\n",
    "# face_landmarks_dat_filepath = \"./models/shape_predictor_68_face_landmarks.dat\"\n",
    "# human_pose_prototxt_filepath = \"./models/pose_deploy_linevec.prototxt\"\n",
    "# human_pose_caffemodel_filepath = \"./models/pose_iter_440000.caffemodel\"\n",
    "\n",
    "\n",
    "# OPTION2: read it in from the config.json file\n",
    "with open(\"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "# Due to compute we don't process every frame but every Xth frame\n",
    "processed_Xth_frame = config[\"processed_Xth_frame\"]\n",
    "\n",
    "# Specify the input image dimensions\n",
    "frameWidth = config[\"frameWidth\"]\n",
    "frameHeight = config[\"frameHeight\"]\n",
    "\n",
    "# Thresholds for the rule-based model\n",
    "eye_threshold_in_pixels = config[\"eye_threshold_in_pixels\"]\n",
    "tilt_frontback_threshold_in_pixels = config[\"tilt_frontback_threshold_in_pixels\"]\n",
    "tilt_leftright_threshold_in_degrees = config[\"tilt_leftright_threshold_in_degrees\"]\n",
    "tilt_shoulder_threshold_in_pixels = config[\"tilt_shoulder_threshold_in_pixels\"]\n",
    "overall_okay_threshold = config[\"overall_okay_threshold\"]\n",
    "\n",
    "# The duration in seconds before...\n",
    "# The alarm is sounded for wrong posture.\n",
    "wrong_posture_duration_in_seconds = config[\"wrong_posture_duration_in_seconds\"]\n",
    "# The text asks you to get up and move.\n",
    "seated_duration_in_seconds = config[\"seated_duration_in_seconds\"]\n",
    "\n",
    "soundclip_filepath = config[\"soundclip_filepath\"]\n",
    "face_landmarks_dat_filepath = config[\"face_landmarks_dat_filepath\"]\n",
    "human_pose_prototxt_filepath = config[\"human_pose_prototxt_filepath\"]\n",
    "human_pose_caffemodel_filepath = config[\"human_pose_caffemodel_filepath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR FACIAL LANDMARK ESTIMATION #\n",
    "# initialize dlib's face detector (HOG-based) and then create the facial landmark predictor\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(face_landmarks_dat_filepath)\n",
    "\n",
    "# FOR HUMAN POSE ESTIMATION #\n",
    "print(\"[INFO] loading human pose predictor...\")\n",
    "# Read the network into Memory\n",
    "net = cv2.dnn.readNetFromCaffe(human_pose_prototxt_filepath, human_pose_caffemodel_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# FOR HUMAN POSE ESTIMATION #\n",
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def plotPrMap(image, maps, swapRB=True, channel=1):\n",
    "    pMap = maps[0, channel, :, :]\n",
    "    \n",
    "    (height, width, _) = image.shape\n",
    "    pMap = cv2.resize(pMap, (width, height))\n",
    "    plt.figure()\n",
    "    \n",
    "    if swapRB:\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    plt.imshow(pMap, alpha=0.6)\n",
    "    plt.axis('off')\n",
    "\n",
    "def searchPts(prMap, prThres=0.1):\n",
    "    blur = cv2.GaussianBlur(prMap, (3,3), 0, 0)\n",
    "    mask = np.uint8(blur > prThres)\n",
    "    pts = []\n",
    "    \n",
    "    if cv2.__version__ == '3.4.2':\n",
    "        (_, ctrs, _) = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        (ctrs, _) = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    for ctr in ctrs:\n",
    "        blobs = np.zeros(mask.shape)\n",
    "        blobs = cv2.fillConvexPoly(blobs, ctr, 1)\n",
    "        blob = blur*blobs\n",
    "        \n",
    "        (_,maxVal,_,maxLoc)  = cv2.minMaxLoc(blob)       \n",
    "        #print(cv2.minMaxLoc(blob))\n",
    "        pts.append(maxLoc + (prMap[maxLoc[1],maxLoc[0]],))\n",
    "    \n",
    "    return (pts, mask)\n",
    "\n",
    "def getAllPoints(cfMaps, imgWidth, imgHeight, cfThres=0.1, numOfKeyPts=18):\n",
    "    ptGrp = []\n",
    "    ptList = np.zeros((0,3))\n",
    "    idx = 0\n",
    "    \n",
    "    for keyPts in range(numOfKeyPts):\n",
    "        prMap = cfMaps[0, keyPts, :, :]\n",
    "        prMap = cv2.resize(prMap, (imgWidth, imgHeight))\n",
    "        \n",
    "        (pts,_) = searchPts(prMap, prThres=cfThres)\n",
    "        \n",
    "        ptWithId = []\n",
    "        for pt in range(len(pts)):\n",
    "            ptWithId.append(pts[pt] + (idx, ))\n",
    "            plList = np.vstack([ptList, pts[pt]])\n",
    "            idx = idx+1\n",
    "            \n",
    "        ptGrp.append(ptWithId)\n",
    "    return (ptGrp, ptList)\n",
    "\n",
    "def plotKeyPoints(image, pointGrp):\n",
    "    for i in range(len(pointGrp)):\n",
    "        for j in range(len(pointGrp[i])):\n",
    "            cv2.circle(image, pointGrp[i][j][0:2], 5, [255,255,255], -1, cv2.LINE_AA)\n",
    "            cv2.circle(image, pointGrp[i][j][0:2], 5, [255, 0, 0], 15, cv2.LINE_AA)\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.imshow(image)\n",
    "    #plt.axis('off')\n",
    "    cv2.imshow(\"Output-Keypoints\",convertToRGB(image))\n",
    "        \n",
    "def sitStraightDetection(img, net):\n",
    "    #set up model\n",
    "    (H, W, _) = img.shape\n",
    "\n",
    "    iptH = 60 #368\n",
    "    iptW = int((iptH/H)*W)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image=img,\n",
    "                                scalefactor=1.0/255,\n",
    "                                size=(iptW, iptH),\n",
    "                                mean=(0,0,0),\n",
    "                                swapRB=False,\n",
    "                                crop=False)\n",
    "    net.setInput(blob)\n",
    "    output = net.forward()\n",
    "    \n",
    "    #get point masks\n",
    "    onePrMap = output[0, 2, :, :]\n",
    "    onePrMap = cv2.resize(onePrMap, (W, H))\n",
    "    (pts, mask) = searchPts(onePrMap)\n",
    "    \n",
    "    #get points groups\n",
    "    (ptGrp, ptList) = getAllPoints(cfMaps=output, imgWidth=W, imgHeight=H)\n",
    "    \n",
    "    #display key points\n",
    "    result = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    plotKeyPoints(result, ptGrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For iris extraction \n",
    "def extract_iris_cm_and_centre_of_eye(facial_landmark3743, facial_landmark3844, \\\n",
    "                                      facial_landmark3945, facial_landmark4046, \\\n",
    "                                      facial_landmark4147, facial_landmark4248, \\\n",
    "                                      frameHeight, frameWidth, gray):\n",
    "    # Extract information about the left/right eye\n",
    "    eye_region = np.array([facial_landmark3743, facial_landmark3844, facial_landmark3945,\n",
    "                           facial_landmark4046, facial_landmark4147, facial_landmark4248], np.int32)\n",
    "    eye_mask = np.zeros((frameHeight, frameWidth), np.uint8)\n",
    "    cv2.polylines(eye_mask, [eye_region], True, 255, 2)\n",
    "    cv2.fillPoly(eye_mask, [eye_region], 255)\n",
    "    eye = cv2.bitwise_and(gray, gray, mask=eye_mask)\n",
    "\n",
    "    eye_min_x = np.min(eye_region[:, 0])\n",
    "    eye_max_x = np.max(eye_region[:, 0])\n",
    "    eye_min_y = np.min(eye_region[:, 1])\n",
    "    eye_max_y = np.max(eye_region[:, 1])\n",
    "\n",
    "    eye_grey = eye[eye_min_y: eye_max_y, eye_min_x: eye_max_x]\n",
    "    eye_grey = cv2.GaussianBlur(eye_grey, (1, 1), 0)\n",
    "    #TODO: TBH this threshold sucks, find a better one.\n",
    "    _, eye_threshold1 = cv2.threshold(eye_grey, 3, 1, cv2.THRESH_BINARY_INV) # Get the edges\n",
    "    _, eye_threshold2 = cv2.threshold(eye_grey, 20, 1, cv2.THRESH_BINARY_INV) # Get both the iris + the edges\n",
    "    eye_threshold = eye_threshold2 - eye_threshold1\n",
    "\n",
    "    eye_centre_block = (eye_min_x + int((eye_max_x-eye_min_x)/2), eye_min_y + int((eye_max_y-eye_min_y)/2))\n",
    "    #output = [eye_centre_block, eye_centre_block]\n",
    "    try:\n",
    "        eye_cm_iris = ndimage.measurements.center_of_mass(eye_threshold.T)\n",
    "        eye_cm_iris = (eye_min_x + int(eye_cm_iris[0]), eye_min_y + int(eye_cm_iris[1]))\n",
    "        \n",
    "        output = [eye_centre_block, eye_cm_iris]\n",
    "    except:\n",
    "        output = [eye_centre_block, eye_centre_block]\n",
    "    return output\n",
    "\n",
    "def angle_point9_point_28(point9, point28):\n",
    "    \"\"\"\n",
    "    1) Get length of line between the 2 points\n",
    "    2) Find the point of point28 projected onto a vertical line from point9\n",
    "    3) Find\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    length1 = math.sqrt((point28[0] - point9[0])**2 + (point28[1] - point9[1])**2 )\n",
    "    \n",
    "    projected28 = (point9[0], point28[1])\n",
    "    lengthX = math.sqrt((projected28[0]- point9[0])**2 + (projected28[1] - point9[1])**2 )\n",
    "    \n",
    "    return math.acos(lengthX/length1)*180/math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For counting of duration in general\n",
    "total_count = 0\n",
    "shown_count = 0\n",
    "\n",
    "eyes_not_front_count = 0\n",
    "eyes_okay_count = 0\n",
    "\n",
    "shoulder_slanted_left_count = 0\n",
    "shoulder_slanted_right_count = 0\n",
    "shoulder_okay_count = 0\n",
    "\n",
    "head_too_left_count = 0\n",
    "head_too_right_count = 0\n",
    "head_too_back_count = 0\n",
    "head_too_front_count = 0\n",
    "head_okay_count = 0\n",
    "\n",
    "# For counting of duration for alarm purposes\n",
    "tmp_shoulder_slanted_left_count = 0\n",
    "tmp_shoulder_slanted_right_count = 0\n",
    "\n",
    "tmp_head_too_left_count = 0\n",
    "tmp_head_too_right_count = 0\n",
    "tmp_head_too_back_count = 0\n",
    "tmp_head_too_front_count = 0\n",
    "\n",
    "# For the display options\n",
    "verbose = False\n",
    "small_sized = False\n",
    "debug = False\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "cap = cv2.VideoCapture(0 + cv2.CAP_DSHOW)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if (total_count%processed_Xth_frame == 0):\n",
    "        shown_count += 1\n",
    "        \n",
    "        # If the image is of a different size, resize it\n",
    "        if frame.shape != (frameWidth, frameHeight):\n",
    "            frame = cv2.resize(frame, (frameWidth, frameHeight), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        #flip the image left-right\n",
    "        frame = cv2.flip(frame, 1)  \n",
    "        frame_save = frame\n",
    "        \n",
    "        # Convert to greyscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply the face detector\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        if len(rects) > 0:\n",
    "            rect = rects[0]\n",
    "            rect_saved = rect\n",
    "        elif ('rect' not in locals()) and ('rect' not in globals()):\n",
    "            continue\n",
    "        else:\n",
    "            rect = rect_saved\n",
    "            \n",
    "        # Apply the facial landmarks detector\n",
    "        facial_landmarks = predictor(gray, rect)\n",
    "        facial_landmarks = face_utils.shape_to_np(facial_landmarks)\n",
    "\n",
    "        # the chin\n",
    "        facial_landmark9  = (facial_landmarks[8][0],  facial_landmarks[8][1])\n",
    "        # the t-zone\n",
    "        facial_landmark28 = (facial_landmarks[27][0], facial_landmarks[27][1])\n",
    "        # the left edge of face\n",
    "        facial_landmark1  = (facial_landmarks[0][0],  facial_landmarks[0][1])\n",
    "        # the right edge of face\n",
    "        facial_landmark17 = (facial_landmarks[16][0], facial_landmarks[16][1])\n",
    "        # the left eye\n",
    "        facial_landmark37 = (facial_landmarks[36][0], facial_landmarks[36][1])\n",
    "        facial_landmark38 = (facial_landmarks[37][0], facial_landmarks[37][1])\n",
    "        facial_landmark39 = (facial_landmarks[38][0], facial_landmarks[38][1])\n",
    "        facial_landmark40 = (facial_landmarks[39][0], facial_landmarks[39][1])\n",
    "        facial_landmark41 = (facial_landmarks[40][0], facial_landmarks[40][1])\n",
    "        facial_landmark42 = (facial_landmarks[41][0], facial_landmarks[41][1])\n",
    "        # the rights eye\n",
    "        facial_landmark43 = (facial_landmarks[42][0], facial_landmarks[42][1])\n",
    "        facial_landmark44 = (facial_landmarks[43][0], facial_landmarks[43][1])\n",
    "        facial_landmark45 = (facial_landmarks[44][0], facial_landmarks[44][1])\n",
    "        facial_landmark46 = (facial_landmarks[45][0], facial_landmarks[45][1])\n",
    "        facial_landmark47 = (facial_landmarks[46][0], facial_landmarks[46][1])\n",
    "        facial_landmark48 = (facial_landmarks[47][0], facial_landmarks[47][1])    \n",
    "        \n",
    "        \n",
    "        #############################\n",
    "        # Draw the base traffic light\n",
    "        #############################\n",
    "        if small_sized:\n",
    "            trafficlightWidth = 120\n",
    "            trafficlightHeight = 100\n",
    "            traffic_light = np.ones((trafficlightHeight, trafficlightWidth), dtype=np.int8)*100\n",
    "            traffic_light = np.repeat(traffic_light[:, :, np.newaxis], 3, axis=2)\n",
    "            # for head\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2)-20,int(trafficlightHeight/2)), 10, (0,0,0), -1) # left\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2)+20,int(trafficlightHeight/2)), 10, (0,0,0), -1) # right\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)-20), 10, (0,0,0), -1)    # top\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)), 10, (0,0,0), -1)    # middle\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)+20), 10, (0,0,0), -1)    # bottom\n",
    "            # for shoulder\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2)-20,int(trafficlightHeight/2)+40), 10, (0,0,0), -1) # left\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2)+20,int(trafficlightHeight/2)+40), 10, (0,0,0), -1) # right\n",
    "            cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)+40), 10, (0,0,0), -1)    # middle\n",
    "            \n",
    "        # If not small_sized\n",
    "        # for head\n",
    "        cv2.circle(frame, (int(frameWidth/2)-20,40), 10, (0,0,0), -1) # left\n",
    "        cv2.circle(frame, (int(frameWidth/2)+20,40), 10, (0,0,0), -1) # right\n",
    "        cv2.circle(frame, (int(frameWidth/2),20), 10, (0,0,0), -1)    # top\n",
    "        cv2.circle(frame, (int(frameWidth/2),40), 10, (0,0,0), -1)    # middle\n",
    "        cv2.circle(frame, (int(frameWidth/2),60), 10, (0,0,0), -1)    # bottom\n",
    "        # for shoulder\n",
    "        cv2.circle(frame, (int(frameWidth/2)-20,80), 10, (0,0,0), -1)    # left\n",
    "        cv2.circle(frame, (int(frameWidth/2)+20,80), 10, (0,0,0), -1)    # right\n",
    "        cv2.circle(frame, (int(frameWidth/2),80), 10, (0,0,0), -1)    # middle\n",
    "            \n",
    "            \n",
    "        #########################################################\n",
    "        # => head TILT LEFT/RIGHT, leaned FORWARD/ BACKWARDS <= #\n",
    "        #########################################################\n",
    "        # from the facial landmarks 9 and 28, plot the angle of the face to the verticle\n",
    "        angle_to_vertical = angle_point9_point_28(facial_landmark9, facial_landmark28)\n",
    "        if facial_landmark9[0] < facial_landmark28[0]:\n",
    "            angle_to_vertical_str = \"Angle to vertical: \" + \"+\" + str(round(angle_to_vertical,2))\n",
    "        else:\n",
    "            angle_to_vertical_str = \"Angle to vertical: \" + \"-\" + str(round(angle_to_vertical,2))\n",
    "            \n",
    "        if debug:\n",
    "            cv2.putText(frame, angle_to_vertical_str, (10, frameHeight-80), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "            cv2.line(frame, (facial_landmark9), (facial_landmark28), (255,255,255), 1)\n",
    "            cv2.line(frame, (facial_landmark9), (facial_landmark9[0], facial_landmark28[1]), (255,255,255), 1)\n",
    "        \n",
    "        if angle_to_vertical > tilt_leftright_threshold_in_degrees and facial_landmarks[8][0] < facial_landmarks[27][0]:\n",
    "            head_message = \"(Head) Too much to the RIGHT.\"\n",
    "            head_too_right_count += 1\n",
    "            tmp_head_too_right_count += 1\n",
    "            tmp_head_too_left_count, tmp_head_too_back_count, tmp_head_too_front_count = 0, 0, 0\n",
    "            cv2.circle(frame, (int(frameWidth/2)+20,40), 10, (0,0,255), -1) # right\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2)+20,int(trafficlightHeight/2)), 10, (0,0,255), -1) # right\n",
    "        elif angle_to_vertical > tilt_leftright_threshold_in_degrees and facial_landmark9[0] > facial_landmarks[27][0]:\n",
    "            head_message = \"(Head) Too much to the LEFT.\"\n",
    "            head_too_left_count += 1\n",
    "            tmp_head_too_left_count += 1\n",
    "            tmp_head_too_right_count, tmp_head_too_back_count, tmp_head_too_front_count = 0, 0, 0\n",
    "            cv2.circle(frame, (int(frameWidth/2)-20,40), 10, (0,0,255), -1) # left\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2)-20,int(trafficlightHeight/2)), 10, (0,0,255), -1) # left\n",
    "        elif facial_landmark28[1] - (facial_landmark1[1] + facial_landmark17[1])/2 > tilt_frontback_threshold_in_pixels:\n",
    "            head_message = \"(Head) Too much to the FRONT.\"\n",
    "            head_too_front_count += 1\n",
    "            tmp_head_too_front_count += 1\n",
    "            tmp_head_too_left_count, tmp_head_too_right_count, tmp_head_too_back_count = 0, 0, 0\n",
    "            cv2.circle(frame, (int(frameWidth/2),60), 10, (0,0,255), -1)    # bottom\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)+20), 10, (0,0,255), -1)    # bottom\n",
    "        elif (facial_landmark1[1] + facial_landmark17[1])/2 - facial_landmark28[1] > tilt_frontback_threshold_in_pixels:\n",
    "            head_message = \"(Head) Too much to the BACK.\"\n",
    "            head_too_back_count += 1\n",
    "            tmp_head_too_back_count += 1\n",
    "            tmp_head_too_left_count, tmp_head_too_right_count, tmp_head_too_front_count = 0, 0, 0\n",
    "            cv2.circle(frame, (int(frameWidth/2),20), 10, (0,0,255), -1)    # top\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)-20), 10, (0,0,255), -1)    # top\n",
    "        else:\n",
    "            head_message = \"(Head) You are OKAY!\"\n",
    "            head_okay_count += 1\n",
    "            tmp_head_too_left_count, tmp_head_too_right_count, tmp_head_too_back_count, tmp_head_too_front_count = 0, 0, 0, 0\n",
    "            cv2.circle(frame, (int(frameWidth/2),40), 10, (0,255,0), -1)    # middle\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)), 10, (0,255,0), -1)    # middle\n",
    "        cv2.putText(frame, head_message, (10, frameHeight-60), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1) \n",
    "\n",
    "        \n",
    "        ###################################\n",
    "        # => EYES NOT LOOKING STRAIGHT <= #\n",
    "        ###################################\n",
    "        left_eye_centre_block, left_eye_cm_iris = extract_iris_cm_and_centre_of_eye(facial_landmark37, facial_landmark38,\n",
    "                                                                                    facial_landmark39, facial_landmark40,\n",
    "                                                                                    facial_landmark41, facial_landmark42,\n",
    "                                                                                    frameHeight, frameWidth, gray)\n",
    "        left_eye_x_diff = left_eye_cm_iris[0] - left_eye_centre_block[0] # If positive, means its right of centre\n",
    "        left_eye_y_diff = left_eye_cm_iris[1] - left_eye_centre_block[1] # If positive, means its below of centre\n",
    "\n",
    "        right_eye_centre_block, right_eye_cm_iris = extract_iris_cm_and_centre_of_eye(facial_landmark43, facial_landmark44,\n",
    "                                                                                      facial_landmark45, facial_landmark46,\n",
    "                                                                                      facial_landmark47, facial_landmark48,\n",
    "                                                                                      frameHeight, frameWidth, gray)\n",
    "        right_eye_x_diff = right_eye_cm_iris[0] - right_eye_centre_block[0] # If positive, means its right of centre\n",
    "        right_eye_y_diff = right_eye_cm_iris[1] - right_eye_centre_block[1] # If positive, means its below of centre\n",
    "        \n",
    "        if debug:\n",
    "            left_iris_str = (\"LEFT: %s %s\" %(left_eye_centre_block, left_eye_cm_iris))\n",
    "            right_iris_str = (\"RIGHT: %s %s\" %(right_eye_centre_block, right_eye_cm_iris))\n",
    "            cv2.putText(frame, left_iris_str, (10, frameHeight-120), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "            cv2.putText(frame, right_iris_str, (10, frameHeight-100), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "        \n",
    "        if abs(left_eye_x_diff) > eye_threshold_in_pixels or \\\n",
    "           abs(left_eye_y_diff) > eye_threshold_in_pixels or \\\n",
    "           abs(right_eye_x_diff) > eye_threshold_in_pixels or \\\n",
    "           abs(right_eye_y_diff) > eye_threshold_in_pixels:\n",
    "            if verbose:\n",
    "                frame = cv2.line(frame, left_eye_cm_iris, \\\n",
    "                                 (int(left_eye_cm_iris[0]+left_eye_x_diff*1.25), int(left_eye_cm_iris[1]+left_eye_y_diff*1.25)), \n",
    "                                 (255,255,255), 1)\n",
    "                frame = cv2.line(frame, right_eye_cm_iris, \\\n",
    "                                 (int(right_eye_cm_iris[0]+right_eye_x_diff*1.25), int(right_eye_cm_iris[1]+right_eye_y_diff*1.25)), \n",
    "                                 (255,255,255), 1)\n",
    "            eyes_not_front_count += 1\n",
    "            cv2.circle(frame, (int(frameWidth/2),40), 8, (0,0,255), -1)    # middle\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)), 8, (0,0,255), -1)    # middle\n",
    "        else:\n",
    "            eyes_okay_count += 1\n",
    "            cv2.circle(frame, (int(frameWidth/2),40), 8, (0,255,0), -1)    # middle\n",
    "            if small_sized:\n",
    "                cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2)), 8, (0,255,0), -1)    # middle\n",
    "        \n",
    "        \n",
    "        #################################\n",
    "        # => SHOULDERS NOT  STRAIGHT <= #\n",
    "        #################################\n",
    "        # Apply shoulder detector\n",
    "        iptH = 80 # How much to resize when creating the blob image\n",
    "        iptW = int((iptH/frameHeight)*frameWidth)\n",
    "        blob = cv2.dnn.blobFromImage(image=frame, scalefactor=1.0/255, size=(iptW, iptH), mean=(0,0,0), swapRB=False, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output = net.forward()\n",
    "\n",
    "        #get point masks\n",
    "        onePrMap = output[0, 2, :, :]\n",
    "        onePrMap = cv2.resize(onePrMap, (frameWidth, frameHeight))\n",
    "        (pts, mask) = searchPts(onePrMap)\n",
    "\n",
    "        #get points groups\n",
    "        (ptGrp, ptList) = getAllPoints(cfMaps=output, imgWidth=frameWidth, imgHeight=frameHeight)\n",
    "    \n",
    "        \n",
    "        if len(ptGrp[2]) > 0 and len(ptGrp[5]) > 0:\n",
    "            # the left shoulder\n",
    "            shoulder_landmark2 = (ptGrp[2][0][0], ptGrp[2][0][1])\n",
    "            # the right shoulder\n",
    "            shoulder_landmark5 = (ptGrp[5][0][0], ptGrp[5][0][1])\n",
    "            if shoulder_landmark2[1] - shoulder_landmark5[1] > tilt_shoulder_threshold_in_pixels:\n",
    "                shoulder_message = \"(Shoulder) Too slanted to the RIGHT.\"\n",
    "                shoulder_slanted_right_count += 1\n",
    "                shoulder_slanted_left_count += 1\n",
    "                shoulder_slanted_right_count = 0\n",
    "                cv2.circle(frame, (int(frameWidth/2)+20, 80), 10, (0,0,255), -1)    # right\n",
    "                if small_sized:\n",
    "                    cv2.circle(traffic_light, (int(trafficlightWidth/2+20),int(trafficlightHeight/2+40)), 10, (0,0,255), -1)    # middle\n",
    "            elif shoulder_landmark5[1] - shoulder_landmark2[1] > tilt_shoulder_threshold_in_pixels:\n",
    "                shoulder_message = \"(Shoulder) Too slanted to the LEFT.\"\n",
    "                shoulder_slanted_left_count += 1\n",
    "                shoulder_slanted_right_count += 1\n",
    "                shoulder_slanted_left_count = 0\n",
    "                cv2.circle(frame, (int(frameWidth/2)-20, 80), 10, (0,0,255), -1)    # left\n",
    "                if small_sized:\n",
    "                    cv2.circle(traffic_light, (int(trafficlightWidth/2-20),int(trafficlightHeight/2+40)), 10, (0,0,255), -1)    # middle\n",
    "            else:\n",
    "                shoulder_message = \"(Shoulder) You are OKAY!\"\n",
    "                shoulder_okay_count += 1\n",
    "                shoulder_slanted_left_count, shoulder_slanted_right_count = 0, 0\n",
    "                cv2.circle(frame, (int(frameWidth/2), 80), 10, (0,255,0), -1)    # middle\n",
    "                if small_sized:\n",
    "                    cv2.circle(traffic_light, (int(trafficlightWidth/2),int(trafficlightHeight/2+40)), 10, (0,255,0), -1)    # middle\n",
    "            cv2.putText(frame, shoulder_message, (10, frameHeight-40), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1) \n",
    "        \n",
    "        \n",
    "        ########################################\n",
    "        # => Plot facial/shoulder landmarks <= #\n",
    "        ########################################        \n",
    "        if verbose:\n",
    "            # Plot the facial landmarks\n",
    "            for i in [0,1,2, 14,15,16, 8, 27, 36,37,38,39,40,41, 42,43,44,45,46,47]:\n",
    "                (x, y) = facial_landmarks[i]\n",
    "                cv2.circle(frame, (x, y), 3, (255, 0, 0), -1, cv2.LINE_AA)\n",
    "            # Plot the shoulder landmarks\n",
    "            for i in [1,2,5]:\n",
    "                if len(ptGrp[i]) > 0:\n",
    "                    cv2.circle(frame, ptGrp[i][0][0:2], 3, (255, 0, 0), -1, cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "        ########################\n",
    "        # => Plot timestamp <= #\n",
    "        ########################                   \n",
    "        # Get the current timestamp\n",
    "        t = time.time()\n",
    "        t_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(t))\n",
    "        # Plot the current timestamp\n",
    "        cv2.putText(frame, t_str, (10, frameHeight-20), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)   \n",
    "        \n",
    "\n",
    "        # For sounding of the alarm based on time\n",
    "        tmp_too_count = sum([tmp_head_too_left_count, tmp_head_too_right_count, \\\n",
    "                             tmp_head_too_back_count, tmp_head_too_front_count, \\\n",
    "                             shoulder_slanted_right_count, shoulder_slanted_left_count])\n",
    "        tmp_duration = t - t_start\n",
    "        if tmp_too_count/shown_count*tmp_duration > wrong_posture_duration_in_seconds:\n",
    "            playsound.playsound(soundclip_filepath)\n",
    "\n",
    "        # For sounding of the alarm based on duration\n",
    "        tmp_duration = t - t_start\n",
    "        if tmp_duration > seated_duration_in_seconds:\n",
    "            cv2.putText(frame, \"Please stand up and move!\", (int(frameWidth/2)-140, int(frameHeight/2)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,  0.75, (255,255,255), 1)\n",
    "        \n",
    "        # Put the options on the image\n",
    "        cv2.putText(frame, \"Options: V, Q; S, E; ESC\", (frameWidth-200, frameHeight-20), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "        \n",
    "        # Show the image\n",
    "        if small_sized == False:\n",
    "            cv2.imshow('Output', frame)\n",
    "        elif small_sized == True:\n",
    "            cv2.imshow('Output', traffic_light)\n",
    "\n",
    "    total_count += 1\n",
    "    # turn off if total_count once reaches 10m (if idle?)\n",
    "    if total_count == 10000000:\n",
    "        break\n",
    "        \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27: # ESC key\n",
    "        break\n",
    "    elif c == 118: # V key\n",
    "        verbose = True\n",
    "    elif c == 113: # Q key\n",
    "        verbose = False\n",
    "    elif c == 61: # + key\n",
    "        debug = True\n",
    "        verbose = True\n",
    "    elif c == 45: # - key\n",
    "        debug = False\n",
    "        verbose = False\n",
    "    elif c == 115: # S key\n",
    "        small_sized = True\n",
    "    elif c == 101: # E key\n",
    "        small_sized = False\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "## Visualize the last frame taken with some output metrics\n",
    "t_end = time.time()\n",
    "duration = t_end - t_start\n",
    "time_spent_msg = (\"Total time shown: %1.2fs\" %(duration))\n",
    "eyes_okay_time_msg = (\"(Eyes) Okay: %1.2fs\" %(eyes_okay_count/shown_count*duration))\n",
    "head_too_time_msg1 = (\"(Head) Too (front,back): %1.2fs, %1.2fs\" \n",
    "      %(head_too_front_count/shown_count*duration, head_too_back_count/shown_count*duration))\n",
    "head_too_time_msg2 = (\"(Head) Too (left,right): %1.2fs, %1.2fs\" \n",
    "      %(head_too_left_count/shown_count*duration, head_too_right_count/shown_count*duration))\n",
    "head_okay_time_msg = (\"(Head) Okay: %1.2fs\" %(head_okay_count/shown_count*duration))\n",
    "shoulder_too_time_msg = (\"(Shoulder) Slanted (left,right): %1.2fs, %1.2fs\" \n",
    "      %(shoulder_slanted_left_count/shown_count*duration, shoulder_slanted_right_count/shown_count*duration))\n",
    "shoulder_okay_time_msg = (\"(Shoulder) Okay: %1.2fs\" %(shoulder_okay_count/shown_count*duration))\n",
    "\n",
    "cv2.putText(frame_save, time_spent_msg, (10, 20), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "cv2.putText(frame_save, eyes_okay_time_msg, (10, 40), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "cv2.putText(frame_save, head_too_time_msg1, (10, 60), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "cv2.putText(frame_save, head_too_time_msg2, (10, 80), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "cv2.putText(frame_save, head_okay_time_msg, (10, 100), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "cv2.putText(frame_save, shoulder_too_time_msg, (10, 120), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "cv2.putText(frame_save, shoulder_okay_time_msg, (10, 140), cv2.FONT_HERSHEY_SIMPLEX,  0.5, (255,255,255), 1)\n",
    "\n",
    "overall_okay = (eyes_okay_count/shown_count)*(head_okay_count/shown_count)*(shoulder_okay_count/shown_count)\n",
    "if overall_okay > overall_okay_threshold:\n",
    "    colour = (0,255,0)\n",
    "    overall_okay_time_msg = (\"Overall: %1.2fs/%1.2fs correct, GOOD!\" %(overall_okay*duration, duration))\n",
    "else:\n",
    "    colour = (0,0,255)\n",
    "    overall_okay_time_msg = (\"Overall: %1.2fs/%1.2fs only, IMPROVE!\" %(overall_okay*duration, duration))\n",
    "cv2.putText(frame_save, overall_okay_time_msg, (10, 180), cv2.FONT_HERSHEY_SIMPLEX,  0.5, colour, 1)\n",
    "\n",
    "cv2.imshow('Input', frame_save)\n",
    "cv2.waitKey(30000) # Hold the final frame for 30s\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
